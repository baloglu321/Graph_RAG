import os
import nest_asyncio
from llama_index.core import PropertyGraphIndex, Settings
from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore
from llama_index.llms.ollama import Ollama
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.core import PromptTemplate
import time

# Async hatasÄ±nÄ± Ã¶nle
nest_asyncio.apply()
CLOUDFLARE_TUNNEL_URL = "https://western-differently-salary-chem.trycloudflare.com/" 
OLLAMA_MODEL_ID = "gemma3:27b"
# ---------------------------------------------------------
# 1. AYARLAR
# ---------------------------------------------------------
JSON_DIR = "./database"       # JSON dosyalarÄ±nÄ±n olduÄŸu klasÃ¶r
STATE_FILE = "file_state.json" # Hangi dosyanÄ±n iÅŸlendiÄŸini tutan hafÄ±za dosyasÄ±


# ---------------------------------------------------------
# 1. AYARLAR (Database koduyla BÄ°REBÄ°R AYNI olmalÄ±)
# ---------------------------------------------------------
print("âš™ï¸  Ayarlar yÃ¼kleniyor...")

# LLM: Llama 3.1 8b
Settings.llm = Ollama(
    model=OLLAMA_MODEL_ID, 
    base_url=CLOUDFLARE_TUNNEL_URL, 
    request_timeout=3000.0,
    temperature=0.1
)

# Embedding: Database'de ne kullandÄ±ysan AYNISI olmalÄ±
Settings.embed_model = HuggingFaceEmbedding(
    model_name="paraphrase-multilingual-mpnet-base-v2"
)

# ---------------------------------------------------------
# 2. NEO4J BAÄLANTISI
# ---------------------------------------------------------
graph_store = Neo4jPropertyGraphStore(
    username="neo4j",
    password="abcd1234",  # Åifreni buraya yaz
    url="bolt://localhost:7687",
)

# ---------------------------------------------------------
# 3. GRAPH'I YÃœKLE (INDEX LOADING)
# ---------------------------------------------------------
print("ğŸ”Œ VeritabanÄ±na baÄŸlanÄ±lÄ±yor...")

# "from_documents" YERÄ°NE "from_existing" kullanÄ±yoruz.
# Bu, veriyi yeniden yazmaz, sadece var olanÄ± okur.
index = PropertyGraphIndex.from_existing(
    property_graph_store=graph_store,
    embed_model=Settings.embed_model,
    llm=Settings.llm
)

print("âœ… BaÄŸlantÄ± baÅŸarÄ±lÄ±! Sohbet baÅŸlÄ±yor...\n")

# ---------------------------------------------------------
# 4. SORGULAMA MOTORU
# ---------------------------------------------------------
# include_text=True: Hem graph iliÅŸkilerine bak hem de orijinal metne bak (Hybrid Search)
query_engine = index.as_query_engine(
    include_text=True, 
    similarity_top_k=3, # En benzer 3 metni getir
)

def get_answer(question):

    try:
        start_time=time.time()
        response = query_engine.query(question)
        stop_time=time.time()
        elapsed_time=stop_time-start_time

        print(f"\nâ­ï¸ CEVAP:\n{response}")
        print(f"â±ï¸  Cevap SÃ¼resi: {elapsed_time:.2f} saniye")
        print("\nğŸ“„ Kaynaklar:")
        for node in response.source_nodes:
            print(f"- {node.text[:100]}...")
    except Exception as e:
        print(f"âŒ Hata: {e}")

# ---------------------------------------------------------
# 5. SOHBET DÃ–NGÃœSÃœ
# ---------------------------------------------------------
if __name__ == "__main__":
    get_answer( 
    question="Normanlar ile Vikingler arasÄ±nda nasÄ±l bir iliÅŸki vardÄ±r?")

    get_answer( 
    question="NormanlarÄ±n dini inancÄ± ve dili hakkÄ±nda bilgi ver.")

    get_answer( 
    question="NormanlarÄ±n Frenklerle bir etkileÅŸimi olmuÅŸ mudur?")